{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: center\"> Introduction to Python\n",
    "\n",
    "## <div style=\"text-align: center\">Introduction to Python (IV)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Web Scraping\n",
    "\n",
    "To do web scraping with Pandas, you can use the `read_html()` function, which can read HTML tables into a Pandas DataFrame."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue install all the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ssl \n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup, element\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "URL = \"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population\"\n",
    "\n",
    "dfs = pd.read_html(URL, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country / Dependency</th>\n",
       "      <th>Population</th>\n",
       "      <th>Population.1</th>\n",
       "      <th>Date</th>\n",
       "      <th>Source (official or from the United Nations)</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rank</td>\n",
       "      <td>Country / Dependency</td>\n",
       "      <td>Numbers</td>\n",
       "      <td>% of the world</td>\n",
       "      <td>Date</td>\n",
       "      <td>Source (official or from the United Nations)</td>\n",
       "      <td>Notes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–</td>\n",
       "      <td>World</td>\n",
       "      <td>8028888000</td>\n",
       "      <td>100%</td>\n",
       "      <td>28 Apr 2023</td>\n",
       "      <td>UN projection[3]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>China</td>\n",
       "      <td>1411750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31 Dec 2022</td>\n",
       "      <td>Official estimate[4]</td>\n",
       "      <td>[b]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>India</td>\n",
       "      <td>1392329000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 Mar 2023</td>\n",
       "      <td>Official projection[5]</td>\n",
       "      <td>[c]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>United States</td>\n",
       "      <td>334683000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28 Apr 2023</td>\n",
       "      <td>National population clock[7]</td>\n",
       "      <td>[d]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank  Country / Dependency  Population    Population.1         Date  \\\n",
       "0  Rank  Country / Dependency     Numbers  % of the world         Date   \n",
       "1     –                 World  8028888000            100%  28 Apr 2023   \n",
       "2     1                 China  1411750000             NaN  31 Dec 2022   \n",
       "3     2                 India  1392329000             NaN   1 Mar 2023   \n",
       "4     3         United States   334683000             NaN  28 Apr 2023   \n",
       "\n",
       "   Source (official or from the United Nations)  Notes  \n",
       "0  Source (official or from the United Nations)  Notes  \n",
       "1                              UN projection[3]    NaN  \n",
       "2                          Official estimate[4]    [b]  \n",
       "3                        Official projection[5]    [c]  \n",
       "4                  National population clock[7]    [d]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[1].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to recognize a table in HTML\n",
    "\n",
    "In HTML, tables are represented by the `<table>` tag. Each row is represented by the `<tr>` tag. A header is represented by the `<th>` tag. A cell is represented by the `<td>` tag.\n",
    "\n",
    "In order to access the DOM of the webpage, you can use Developer Tools in your browser. In Chrome, you can access it by right-clicking on the page and selecting \"Inspect\". In Firefox, you can access it by right-clicking on the page and selecting \"Inspect Element\". In Safari, you can access it by right-clicking on the page and selecting \"Inspect Element\".\n",
    "\n",
    "[Learn more about developer tools](https://developer.mozilla.org/en-US/docs/Learn/Common_questions/What_are_browser_developer_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dfs \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_html(\u001b[39m'\u001b[39;49m\u001b[39mhttps://www.xxl.se/faq/cookies\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/html.py:1205\u001b[0m, in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links)\u001b[0m\n\u001b[1;32m   1201\u001b[0m validate_header_arg(header)\n\u001b[1;32m   1203\u001b[0m io \u001b[39m=\u001b[39m stringify_path(io)\n\u001b[0;32m-> 1205\u001b[0m \u001b[39mreturn\u001b[39;00m _parse(\n\u001b[1;32m   1206\u001b[0m     flavor\u001b[39m=\u001b[39;49mflavor,\n\u001b[1;32m   1207\u001b[0m     io\u001b[39m=\u001b[39;49mio,\n\u001b[1;32m   1208\u001b[0m     match\u001b[39m=\u001b[39;49mmatch,\n\u001b[1;32m   1209\u001b[0m     header\u001b[39m=\u001b[39;49mheader,\n\u001b[1;32m   1210\u001b[0m     index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m   1211\u001b[0m     skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[1;32m   1212\u001b[0m     parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m   1213\u001b[0m     thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[1;32m   1214\u001b[0m     attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1215\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   1216\u001b[0m     decimal\u001b[39m=\u001b[39;49mdecimal,\n\u001b[1;32m   1217\u001b[0m     converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[1;32m   1218\u001b[0m     na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[1;32m   1219\u001b[0m     keep_default_na\u001b[39m=\u001b[39;49mkeep_default_na,\n\u001b[1;32m   1220\u001b[0m     displayed_only\u001b[39m=\u001b[39;49mdisplayed_only,\n\u001b[1;32m   1221\u001b[0m     extract_links\u001b[39m=\u001b[39;49mextract_links,\n\u001b[1;32m   1222\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/html.py:1006\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1005\u001b[0m     \u001b[39massert\u001b[39;00m retained \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m  \u001b[39m# for mypy\u001b[39;00m\n\u001b[0;32m-> 1006\u001b[0m     \u001b[39mraise\u001b[39;00m retained\n\u001b[1;32m   1008\u001b[0m ret \u001b[39m=\u001b[39m []\n\u001b[1;32m   1009\u001b[0m \u001b[39mfor\u001b[39;00m table \u001b[39min\u001b[39;00m tables:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/html.py:986\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m p \u001b[39m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only, extract_links)\n\u001b[1;32m    985\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 986\u001b[0m     tables \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mparse_tables()\n\u001b[1;32m    987\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m caught:\n\u001b[1;32m    988\u001b[0m     \u001b[39m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[39m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[1;32m    990\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(io, \u001b[39m\"\u001b[39m\u001b[39mseekable\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m io\u001b[39m.\u001b[39mseekable():\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/html.py:262\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_tables\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m     tables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_tables(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_doc(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmatch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattrs)\n\u001b[1;32m    263\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[39mfor\u001b[39;00m table \u001b[39min\u001b[39;00m tables)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/html.py:618\u001b[0m, in \u001b[0;36m_BeautifulSoupHtml5LibFrameParser._parse_tables\u001b[0;34m(self, doc, match, attrs)\u001b[0m\n\u001b[1;32m    615\u001b[0m tables \u001b[39m=\u001b[39m doc\u001b[39m.\u001b[39mfind_all(element_name, attrs\u001b[39m=\u001b[39mattrs)\n\u001b[1;32m    617\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tables:\n\u001b[0;32m--> 618\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo tables found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    620\u001b[0m result \u001b[39m=\u001b[39m []\n\u001b[1;32m    621\u001b[0m unique_tables \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: No tables found"
     ]
    }
   ],
   "source": [
    "dfs = pd.read_html('https://www.xxl.se/faq/cookies')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did we get error of no tables found? \n",
    "\n",
    "Some websites use JavaScript to load data. It means that content is being loaded dynamically. The `read_html()` function can only read Websites that serve content 'onload'. It cannot read data loaded by JavaScript. If you want to scrape data from a website that uses JavaScript to load data, you will need to use a different library, such as Selenium.\n",
    "\n",
    "You can observe the HTML code received in `read_html()` by reading Page Source in your browser. In browser, you can access it by right-clicking on the page and selecting \"View Page Source\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">**TASK**</span>\n",
    "\n",
    "Read the table from the following website: \n",
    "https://www.icc-cricket.com/rankings/mens/team-rankings/odi\n",
    "\n",
    "Find out which team has the highest amount of points and which team played least amount of matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "\n",
    "# Code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requests\n",
    "---\n",
    "\n",
    "#### How does the requesting work?\n",
    "\n",
    "The request is sent from the client to the server. The client is the computer that is requesting the data. The server is the computer that is providing the data. The client sends a request to the server, and the server responds with the requested data.\n",
    "\n",
    "<details>\n",
    "  <summary style=\"margin-block: 16px; font-size: 1.5rem;\">OSI Model</summary>\n",
    "  The OSI (Open Systems Interconnection) model is a conceptual framework used to describe the communication process between networked devices. The model is divided into seven layers, each responsible for a specific aspect of network communication. When a user creates a request to a server, the request goes through each of the layers of the OSI model.\n",
    "\n",
    "At the Application layer, the user's application creates a request that includes the desired action, such as requesting a web page. The request is then passed to the Presentation layer, where the data is formatted into a standard representation that can be understood by both the sender and receiver.\n",
    "\n",
    "The Session layer establishes, maintains, and terminates connections between the user's device and the server. Next, the Transport layer breaks the request into smaller packets, assigns sequence numbers to each packet, and ensures that they are transmitted in the correct order.\n",
    "\n",
    "The Network layer is responsible for routing the packets across the network, using logical addressing to identify the destination device. The Data Link layer is responsible for moving the packets between adjacent devices, using physical addressing. Finally, the Physical layer defines the physical medium over which the packets are transmitted, such as Ethernet or Wi-Fi.\n",
    "\n",
    "When the request reaches the server, the process is reversed. The Physical layer receives the packets, which are then processed by the Data Link layer, the Network layer, and so on, until the request reaches the Application layer on the server. The server then sends a response back to the user, which goes through the same process in reverse order.\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "  <img src=\"https://shardeum.org/blog/wp-content/uploads/2022/09/The-Physical-Layer-in-OSI-Model-Explained-thumbnail.jpg\"  style=\"width:700px\"/>\n",
    "</div>\n",
    "\n",
    "The requests library in Python is a popular library for making HTTP requests, which allows you to send HTTP/1.1 requests. It abstracts the complexities of making requests behind a simple API, allowing you to send HTTP/1.1 requests using Python.\n",
    "\n",
    "Here are a few key features of the `requests` library:\n",
    "\n",
    "- Easy to use API: The requests library provides a simple and intuitive API for sending HTTP requests and handling HTTP responses. You can send GET, POST, PUT, DELETE, and other HTTP requests with just a few lines of code.\n",
    "\n",
    "- Support for different types of data: The requests library allows you to send and receive data in different formats, including JSON, XML, and plain text. You can also send and receive binary data, such as images and files.\n",
    "\n",
    "- Support for authentication and security: The requests library supports various types of authentication and security, including basic and digest authentication, SSL/TLS encryption, and session management.\n",
    "\n",
    "- Customizable: The requests library provides a variety of options for customizing HTTP requests, such as setting headers, cookies, proxies, and timeouts.\n",
    "\n",
    "[Documentation](https://requests.readthedocs.io/en/master/)\n",
    "\n",
    "Here is a simple example of how to use the requests library to send a GET request and retrieve data from an API:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Send a GET request to the API\n",
    "response = requests.get('https://jsonplaceholder.typicode.com/posts/1')\n",
    "\n",
    "# Check the status code of the response\n",
    "if response.status_code == 200:\n",
    "    # Retrieve the data from the response\n",
    "    data = response.json()\n",
    "    \n",
    "    # Print the data\n",
    "    print(json.dumps(\n",
    "    data,\n",
    "    sort_keys=True,\n",
    "    indent=4,\n",
    "    separators=(',', ': ')\n",
    "))\n",
    "\n",
    "else:\n",
    "    # Handle any errors\n",
    "    print('Error:', response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST Method\n",
    "This method is used to send data to the server, for example, customer information, file upload, etc. Using the data parameter, we can define what data to send to the server.\n",
    "\n",
    "We can send data in different formats, such as JSON, XML, plain text, etc. The data parameter accepts a dictionary, a list of tuples, bytes, or a file-like object. If you want to send data in JSON format, you can use the json parameter instead of the data parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a POST request to the API\n",
    "response = requests.post('https://jsonplaceholder.typicode.com/posts', data = {'title': 'Test POST method', 'body': 'This is a test of the POST method', 'userId': 1})\n",
    "\n",
    "# Check the status code of the response\n",
    "if response.status_code == 201:\n",
    "    # Retrieve the data from the response\n",
    "    data = response.json()\n",
    "    \n",
    "    # Print the data\n",
    "    print(json.dumps(\n",
    "    data,\n",
    "    sort_keys=True,\n",
    "    indent=4,\n",
    "    separators=(',', ': ')\n",
    "))\n",
    "\n",
    "else:\n",
    "    # Handle any errors\n",
    "    print('Error:', response.status_code)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">**TASK**</span>\n",
    "\n",
    "Visit the [Genderize.io](https://genderize.io/) and [Agify.io](https://agify.io/) take a look at usage of the API.\n",
    "\n",
    "Using this API find gender, age and probabilities for names of the characters in the Family Guy TV show. Remember to add set location query parameter to US to get more accurate results.\n",
    "\n",
    "Save the results in a DataFrame and save it as a csv file. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_guy_characters = list(['Peter', 'Lois', 'Chris', 'Meg', 'Stewie', 'Brian', 'Glenn', 'Cleveland', 'Joe', 'Herbert', 'Tom', 'Bert'])\n",
    "\n",
    "#  Code goes here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find more free API in [this list](https://mixedanalytics.com/blog/list-actually-free-open-no-auth-needed-apis/). Most of the API are free to use, but some of them require registration and API key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL Process (Extract, Transform, Load)\n",
    "---\n",
    "\n",
    "ETL stands for Extract, Transform, Load and refers to the process of extracting data from one or more sources, transforming it into a format suitable for analysis, and loading it into a target database or data warehouse. The following is a simple demonstration of ETL process in Python using the popular libraries Pandas or SQLAlchemy.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/f/fa/Conventional_ETL_Diagram.jpg\"  style=\"width:700px\"/>\n",
    "</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading environment variables\n",
    "\n",
    "In order to keep our API keys and other sensitive information safe, we will store them in environment variables. We will use the `os` and `dotenv` library to access environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN_WEATHER_API_KEY = os.getenv('OPEN_WEATHER_API_KEY')\n",
    "DAILY_FORECAST_URL = f\"https://api.openweathermap.org/data/2.5/forecast\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in the ETL process is to extract data from one or more sources. We will extract data from the API request to the OpenWeatherMap API. First load the capital cities of the world from the `european-capitals.csv` file into a Pandas DataFrame. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_forecast_url_builder(lat, lon):\n",
    "    return f\"{DAILY_FORECAST_URL}?lat={lat}&lon={lon}&appid={OPEN_WEATHER_API_KEY}&units=metric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_forecast(lat, lon):\n",
    "    url = daily_forecast_url_builder(lat, lon)\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = daily_forecast_url_builder(52.520008, 13.404954)\n",
    "res = requests.get(url).json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">**TASK**</span>\n",
    "\n",
    "1. Take a look into how the JSON response looks like. Build a function that returns a dictionary with the following data:\n",
    "\n",
    "    - City name\n",
    "    - Country name\n",
    "    - Temperature\n",
    "    - Humidity\n",
    "    - Wind speed\n",
    "    - Cloudiness\n",
    "    - Datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code goes here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">**TASK**</span>\n",
    "\n",
    "1. Load the `european-capitals.csv` file into a Pandas DataFrame.\n",
    "2. Iterate over the DataFrame and make a request to the OpenWeatherMap API for each city. Use the prepared functions `daily_forecast_url_builder` and `get_daily_forecast`.\n",
    "\n",
    "\n",
    "_Hint: Use `.iterrows()` method to iterate over the DataFrame. Save the data to a list of dictionaries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_weather_list = []\n",
    "\n",
    "# Code goes here\n",
    "\n",
    "city_weather_df = pd.DataFrame(city_weather_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tirana</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2023-04-24 15:00:00</td>\n",
       "      <td>18.51</td>\n",
       "      <td>48</td>\n",
       "      <td>5.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tirana</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2023-04-24 18:00:00</td>\n",
       "      <td>17.22</td>\n",
       "      <td>59</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tirana</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2023-04-24 21:00:00</td>\n",
       "      <td>14.92</td>\n",
       "      <td>76</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tirana</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2023-04-25 00:00:00</td>\n",
       "      <td>12.34</td>\n",
       "      <td>90</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tirana</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2023-04-25 03:00:00</td>\n",
       "      <td>12.38</td>\n",
       "      <td>89</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>2023-04-29 00:00:00</td>\n",
       "      <td>14.04</td>\n",
       "      <td>83</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>2023-04-29 03:00:00</td>\n",
       "      <td>14.83</td>\n",
       "      <td>76</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>2023-04-29 06:00:00</td>\n",
       "      <td>16.27</td>\n",
       "      <td>71</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>2023-04-29 09:00:00</td>\n",
       "      <td>20.99</td>\n",
       "      <td>48</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>2023-04-29 12:00:00</td>\n",
       "      <td>24.91</td>\n",
       "      <td>31</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                City  Country                 Date  Temperature  Humidity  \\\n",
       "0             Tirana  Albania  2023-04-24 15:00:00        18.51        48   \n",
       "1             Tirana  Albania  2023-04-24 18:00:00        17.22        59   \n",
       "2             Tirana  Albania  2023-04-24 21:00:00        14.92        76   \n",
       "3             Tirana  Albania  2023-04-25 00:00:00        12.34        90   \n",
       "4             Tirana  Albania  2023-04-25 03:00:00        12.38        89   \n",
       "..               ...      ...                  ...          ...       ...   \n",
       "75  Andorra la Vella  Andorra  2023-04-29 00:00:00        14.04        83   \n",
       "76  Andorra la Vella  Andorra  2023-04-29 03:00:00        14.83        76   \n",
       "77  Andorra la Vella  Andorra  2023-04-29 06:00:00        16.27        71   \n",
       "78  Andorra la Vella  Andorra  2023-04-29 09:00:00        20.99        48   \n",
       "79  Andorra la Vella  Andorra  2023-04-29 12:00:00        24.91        31   \n",
       "\n",
       "    Wind Speed  \n",
       "0         5.16  \n",
       "1         1.07  \n",
       "2         1.36  \n",
       "3         1.32  \n",
       "4         1.74  \n",
       "..         ...  \n",
       "75        0.28  \n",
       "76        0.21  \n",
       "77        0.40  \n",
       "78        3.21  \n",
       "79        5.37  \n",
       "\n",
       "[80 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform\n",
    "\n",
    "The second step in the ETL process is to transform the data into a format suitable for analysis. We will transform by stripping the time from the date column. We will also find the minimum, maximum, and average temperature for Tirana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Strip time from date\n",
    "city_weather_df['Date'] = city_weather_df['Date'].str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average, min and max temperature for Tirana for each day\n",
    "city_weather_df[city_weather_df['City'] == 'Tirana'].groupby('Date').agg({\n",
    "    'Temperature': ['mean', 'min', 'max']\n",
    "}).plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">**TASK**</span>\n",
    "\n",
    "- Find a city with the highest average temperature. What is the name of the city and what is the average temperature?\n",
    "- Find a city in the DataFrame that has the most often cloudy weather. What is the name of the city and what is the percentage of cloudy days?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load\n",
    "\n",
    "Here's an example of how you could save a Pandas DataFrame to a SQLite database using SQLAlchemy, and then read it back:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_weather_df.to_csv('european_capitals_weather.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'city_weather_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Create an SQLite database engine\u001b[39;00m\n\u001b[1;32m      4\u001b[0m engine \u001b[39m=\u001b[39m create_engine(\u001b[39m'\u001b[39m\u001b[39msqlite:///weather.db\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m city_weather_df\u001b[39m.\u001b[39mto_sql(\u001b[39m'\u001b[39m\u001b[39mweather_data\u001b[39m\u001b[39m'\u001b[39m, engine, if_exists\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mreplace\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mSELECT * FROM weather_data WHERE City = \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTirana\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     10\u001b[0m city_weather_df_from_sql \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_sql_query(sql\u001b[39m=\u001b[39mtext(query), con\u001b[39m=\u001b[39mengine\u001b[39m.\u001b[39mconnect())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'city_weather_df' is not defined"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Create an SQLite database engine\n",
    "engine = create_engine('sqlite:///weather.db')\n",
    "city_weather_df.to_sql('weather_data', engine, if_exists='replace')\n",
    "\n",
    "\n",
    "query = 'SELECT * FROM weather_data WHERE City = \"Tirana\"'\n",
    "\n",
    "city_weather_df_from_sql = pd.read_sql_query(sql=text(query), con=engine.connect())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the pandas library is used to create a DataFrame and save it to a SQLite database using SQLAlchemy. \n",
    "\n",
    "The `create_engine` function is used to create a SQLAlchemy engine that connects to the SQLite database `weather.db`. The `city_weather_df.to_sql` method is used to save the DataFrame to a table named `weather_data` in the database. If the table already exists, it will be replaced. \n",
    " \n",
    "The `pd.read_sql_table` function is used to read the data from the SQLite database back into a DataFrame, and the print function is used to display the contents of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2023-04-24 15:00:00</td>\n",
       "      <td>18.51</td>\n",
       "      <td>48</td>\n",
       "      <td>5.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2023-04-24 18:00:00</td>\n",
       "      <td>17.22</td>\n",
       "      <td>59</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2023-04-24 21:00:00</td>\n",
       "      <td>14.92</td>\n",
       "      <td>76</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2023-04-25 00:00:00</td>\n",
       "      <td>12.34</td>\n",
       "      <td>90</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2023-04-25 03:00:00</td>\n",
       "      <td>12.38</td>\n",
       "      <td>89</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>2023-04-29 00:00:00</td>\n",
       "      <td>14.04</td>\n",
       "      <td>83</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>2023-04-29 03:00:00</td>\n",
       "      <td>14.83</td>\n",
       "      <td>76</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>2023-04-29 06:00:00</td>\n",
       "      <td>16.27</td>\n",
       "      <td>71</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>2023-04-29 09:00:00</td>\n",
       "      <td>20.99</td>\n",
       "      <td>48</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>2023-04-29 12:00:00</td>\n",
       "      <td>24.91</td>\n",
       "      <td>31</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index              City  Country                 Date  Temperature  \\\n",
       "0       0            Tirana  Albania  2023-04-24 15:00:00        18.51   \n",
       "1       1            Tirana  Albania  2023-04-24 18:00:00        17.22   \n",
       "2       2            Tirana  Albania  2023-04-24 21:00:00        14.92   \n",
       "3       3            Tirana  Albania  2023-04-25 00:00:00        12.34   \n",
       "4       4            Tirana  Albania  2023-04-25 03:00:00        12.38   \n",
       "..    ...               ...      ...                  ...          ...   \n",
       "75     75  Andorra la Vella  Andorra  2023-04-29 00:00:00        14.04   \n",
       "76     76  Andorra la Vella  Andorra  2023-04-29 03:00:00        14.83   \n",
       "77     77  Andorra la Vella  Andorra  2023-04-29 06:00:00        16.27   \n",
       "78     78  Andorra la Vella  Andorra  2023-04-29 09:00:00        20.99   \n",
       "79     79  Andorra la Vella  Andorra  2023-04-29 12:00:00        24.91   \n",
       "\n",
       "    Humidity  Wind Speed  \n",
       "0         48        5.16  \n",
       "1         59        1.07  \n",
       "2         76        1.36  \n",
       "3         90        1.32  \n",
       "4         89        1.74  \n",
       "..       ...         ...  \n",
       "75        83        0.28  \n",
       "76        76        0.21  \n",
       "77        71        0.40  \n",
       "78        48        3.21  \n",
       "79        31        5.37  \n",
       "\n",
       "[80 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_weather_df_from_sql"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requesting the webpages\n",
    "\n",
    "In this section, we will use the `requests` library to make HTTP requests to the webpages of the capital cities of the world. We will use the `BeautifulSoup` library to parse the HTML and extract the data we need.\n",
    "\n",
    "It is possible to see what the HTML code of a webpage looks like by right-clicking on the page and selecting \"View Page Source\" from the context menu. The HTML code of a webpage is displayed in the browser window.\n",
    "\n",
    "This is exact content that our web scraper will parse and extract the data from plus some data about headers, cookies, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://webscraper.io/test-sites/tables'\n",
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__attrs__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_content',\n",
       " '_content_consumed',\n",
       " '_next',\n",
       " 'apparent_encoding',\n",
       " 'close',\n",
       " 'connection',\n",
       " 'content',\n",
       " 'cookies',\n",
       " 'elapsed',\n",
       " 'encoding',\n",
       " 'headers',\n",
       " 'history',\n",
       " 'is_permanent_redirect',\n",
       " 'is_redirect',\n",
       " 'iter_content',\n",
       " 'iter_lines',\n",
       " 'json',\n",
       " 'links',\n",
       " 'next',\n",
       " 'ok',\n",
       " 'raise_for_status',\n",
       " 'raw',\n",
       " 'reason',\n",
       " 'request',\n",
       " 'status_code',\n",
       " 'text',\n",
       " 'url']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n\\t<!-- Google Tag Manager -->\\n<script>(function (w, d, s, l, i) {\\n\\t\\tw[l] = w[l] || [];\\n\\t\\tw[l].push({\\n\\t\\t\\t\\'gtm.start\\':\\n\\t\\t\\t\\tnew Date().getTime(), event: \\'gtm.js\\'\\n\\t\\t});\\n\\t\\tvar f = d.getElementsByTagName(s)[0],\\n\\t\\t\\tj = d.createElement(s), dl = l != \\'dataLayer\\' ? \\'&l=\\' + l : \\'\\';\\n\\t\\tj.async = true;\\n\\t\\tj.src =\\n\\t\\t\\t\\'https://www.googletagmanager.com/gtm.js?id=\\' + i + dl;\\n\\t\\tf.parentNode.insertBefore(j, f);\\n\\t})(window, document, \\'script\\', \\'dataLayer\\', \\'GTM-NVFPDWB\\');</script>\\n<!-- End Google Tag Manager -->\\n\\t<title>Web Scraper Test Sites</title>\\n\\t<meta charset=\"utf-8\">\\n\\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\\n\\n\\t<meta name=\"keywords\"\\n\\t\\t  content=\"web scraping,Web Scraper,Chrome extension,Crawling,Cross platform scraper\"/>\\n\\t<meta name=\"description\"\\n\\t\\t  content=\"The most popular web scraping extension. Start scraping in minutes. Automate your tasks with our Cloud Scraper. No software to download, no coding needed.\"/>\\n\\t<link rel=\"icon\" sizes=\"128x128\" href=\"/favicon.png\">\\n\\n\\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\\n\\t\\n\\t<link rel=\"stylesheet\" href=\"/css/app.css?id=6174eb2357a19b17c8620448a415ac2b\">\\n\\n\\t<link rel=\"canonical\" href=\"https://webscraper.io/test-sites/tables\">\\n\\t<link rel=\"apple-touch-icon\" href=\"/img/logo-icon.png\">\\n\\n\\t\\t<script defer src=\"/js/app.js?id=8c184229d2180b20f8d41d9110b84b32\"></script>\\n\\n\\t\\n</head>\\n<body>\\n<!-- Google Tag Manager (noscript) -->\\n<noscript>\\n\\t<iframe src=\"https://www.googletagmanager.com/ns.html?id=GTM-NVFPDWB\"\\n\\t        height=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe>\\n</noscript>\\n<!-- End Google Tag Manager (noscript) -->\\n<header role=\"banner\" class=\"navbar navbar-fixed-top navbar-static\">\\n\\t<div class=\"container\">\\n\\n\\t\\t<div class=\"navbar-header\">\\n\\n\\t\\t\\t<a data-toggle=\"collapse-side\" data-target=\".side-collapse\" data-target-2=\".side-collapse-container\">\\n\\t\\t\\t\\t<button type=\"button\" class=\"navbar-toggle pull-right collapsed\" data-toggle=\"collapse\"\\n\\t\\t\\t\\t        data-target=\"#navbar\" data-target-2=\".side-collapse-container\" data-target-3=\".side-collapse\"\\n\\t\\t\\t\\t        aria-expanded=\"false\" aria-controls=\"navbar\">\\n\\n\\t\\t\\t\\t\\t<span class=\"sr-only\">Toggle navigation</span>\\n\\t\\t\\t\\t\\t<span class=\"icon-bar top-bar\"></span>\\n\\t\\t\\t\\t\\t<span class=\"icon-bar middle-bar\"></span>\\n\\t\\t\\t\\t\\t<span class=\"icon-bar bottom-bar\"></span>\\n\\n\\t\\t\\t\\t</button>\\n\\t\\t\\t</a>\\n\\t\\t\\t<div class=\"navbar-brand\">\\n\\t\\t\\t\\t<a href=\"/\"><img src=\"/img/logo_white.svg\" alt=\"Web Scraper\"></a>\\n\\t\\t\\t</div>\\n\\t\\t</div>\\n\\n\\t\\t<div class=\"side-collapse in\">\\n\\t\\t\\t<nav id=\"navbar\" role=\"navigation\" class=\"navbar-collapse collapse\">\\n\\t\\t\\t\\t<ul class=\"nav navbar-nav navbar-right\">\\n\\t\\t\\t\\t\\t<li class=\"hidden\">\\n\\t\\t\\t\\t\\t\\t<a href=\"#page-top\"></a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"/\" class=\"menuitm\">\\n\\t\\t\\t\\t\\t\\t\\t<p>Web Scraper</p>\\n\\t\\t\\t\\t\\t\\t\\t<div class=\"crta\"></div>\\n\\t\\t\\t\\t\\t\\t</a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"/cloud-scraper\" class=\"menuitm\">\\n\\t\\t\\t\\t\\t\\t\\t<p>Cloud Scraper</p>\\n\\t\\t\\t\\t\\t\\t\\t<div class=\"crta\"></div>\\n\\t\\t\\t\\t\\t\\t</a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"/pricing\" class=\"menuitm\">\\n\\t\\t\\t\\t\\t\\t\\t<p>Pricing</p>\\n\\t\\t\\t\\t\\t\\t\\t<div class=\"crta\"></div>\\n\\t\\t\\t\\t\\t\\t</a>\\n\\t\\t\\t\\t\\t</li>\\n\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<li class=\"dropdown\">\\n\\t\\t\\t\\t\\t\\t<a href=\"#section3\" class=\"menuitm dropdown-toggle\" data-toggle=\"dropdown\">\\n\\t\\t\\t\\t\\t\\t\\t<p>Learn</p>\\n\\t\\t\\t\\t\\t\\t\\t<div class=\"crta\"></div>\\n\\t\\t\\t\\t\\t\\t</a>\\n\\t\\t\\t\\t\\t\\t<ul class=\"dropdown-menu\">\\n\\t\\t\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t\\t\\t<a href=\"/documentation\">Documentation</a>\\n\\t\\t\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t\\t\\t<a href=\"/tutorials\">Video Tutorials</a>\\n\\t\\t\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t\\t\\t<a href=\"/how-to-videos\">How to</a>\\n\\t\\t\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t\\t\\t<a href=\"/test-sites\">Test Sites</a>\\n\\t\\t\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t\\t\\t<a href=\"https://forum.webscraper.io/\" target=\"_blank\" rel=\"noopener\">Forum</a>\\n\\t\\t\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t\\t</ul>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"#\" class=\"btn-menu1 install-extension\">Install</a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"https://cloud.webscraper.io/\" class=\"btn-menu2\">Login</a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t</ul>\\n\\t\\t\\t</nav>\\n\\t\\t</div>\\n\\t</div>\\n</header>\\n\\n<div class=\"wrapper\">\\n\\t\\n\\t<div class=\"formenu-here container-fluid\">\\n\\n\\t</div>\\n\\t<div class=\"container-fluid blog-hero\">\\n\\t\\t<div class=\"container\">\\n\\t\\t\\t<div class=\"row\">\\n\\t\\t\\t\\t<div class=\"col-md-12\">\\n\\t\\t\\t\\t\\t<h1>Test Sites</h1>\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t</div>\\n\\t\\t</div>\\n\\t</div>\\n\\n\\t<div class=\"container\">\\n\\t\\t<div class=\"container test-site\">\\n\\t\\t\\t<div class=\"row\">\\n\\t\\t\\t\\t<div class=\"col-md-3 sidebar\">\\n\\t\\t\\t\\t\\t<div class=\"navbar-default sidebar\" role=\"navigation\">\\n\\t\\t\\t\\t\\t\\t<div class=\"sidebar-nav navbar-collapse\">\\n\\t\\t\\t\\t\\t\\t\\t<ul class=\"nav\" id=\"side-menu\">\\n\\t\\t\\t\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t<a href=\"/test-sites/tables/tables-semantically-correct\" class=\"table-nav-button semantically-correct-button   active \">Semantically correct tables</a>\\n\\t\\t\\t\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t<a href=\"/test-sites/tables/tables-without-thead\" class=\"table-nav-button button-without-thead \">Tables without the thead tag</a>\\n\\t\\t\\t\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t<a href=\"/test-sites/tables/tables-multiple-header-rows\" class=\"table-nav-button button-multiple-headers \">Tables with multiple header rows</a>\\n\\t\\t\\t\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t\\t\\t</ul>\\n\\t\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t<div class=\"col-md-9\">\\n\\t\\t\\t\\t\\t<div class=\"tables-all\">\\n\\n\\t\\t\\t\\t\\t\\t<div class=\"jumbotron tables-initial-text\">\\n\\t\\t\\t\\t\\t\\t\\t<h1>Table playground</h1>\\n\\t\\t\\t\\t\\t\\t\\t<p>\\n\\t\\t\\t\\t\\t\\t\\t\\tYou can train using Table selector here.\\n\\t\\t\\t\\t\\t\\t\\t</p>\\n\\t\\t\\t\\t\\t\\t</div>\\n\\n\\t\\t\\t\\t\\t\\t\\t<div class=\"tables-semantically-correct\">\\n\\t\\t<h2>Semantically correct table with thead and tbody</h2>\\n\\t\\t<p>\\n\\t\\t\\tTable selector automatically detects header and data rows.\\n\\t\\t</p>\\n\\n\\t\\t<table class=\"table table-bordered\">\\n\\t\\t\\t<thead>\\n\\t\\t\\t<tr>\\n\\t\\t\\t\\t<th>#</th>\\n\\t\\t\\t\\t<th>First Name</th>\\n\\t\\t\\t\\t<th>Last Name</th>\\n\\t\\t\\t\\t<th>Username</th>\\n\\t\\t\\t</tr>\\n\\t\\t\\t</thead>\\n\\t\\t\\t<tbody>\\n\\t\\t\\t<tr>\\n\\t\\t\\t\\t<td>1</td>\\n\\t\\t\\t\\t<td>Mark</td>\\n\\t\\t\\t\\t<td>Otto</td>\\n\\t\\t\\t\\t<td>@mdo</td>\\n\\t\\t\\t</tr>\\n\\t\\t\\t<tr>\\n\\t\\t\\t\\t<td>2</td>\\n\\t\\t\\t\\t<td>Jacob</td>\\n\\t\\t\\t\\t<td>Thornton</td>\\n\\t\\t\\t\\t<td>@fat</td>\\n\\t\\t\\t</tr>\\n\\t\\t\\t<tr>\\n\\t\\t\\t\\t<td>3</td>\\n\\t\\t\\t\\t<td>Larry</td>\\n\\t\\t\\t\\t<td>the Bird</td>\\n\\t\\t\\t\\t<td>@twitter</td>\\n\\t\\t\\t</tr>\\n\\t\\t\\t</tbody>\\n\\t\\t</table>\\n\\n\\t\\t<table class=\"table table-bordered table-bordered2\">\\n\\t\\t\\t<thead>\\n\\t\\t\\t<tr>\\n\\t\\t\\t\\t<th>#</th>\\n\\t\\t\\t\\t<th>First Name</th>\\n\\t\\t\\t\\t<th>Last Name</th>\\n\\t\\t\\t\\t<th>Username</th>\\n\\t\\t\\t</tr>\\n\\t\\t\\t</thead>\\n\\t\\t\\t<tbody>\\n\\t\\t\\t<tr>\\n\\t\\t\\t\\t<td>4</td>\\n\\t\\t\\t\\t<td>Harry</td>\\n\\t\\t\\t\\t<td>Potter</td>\\n\\t\\t\\t\\t<td>@hp</td>\\n\\t\\t\\t</tr>\\n\\t\\t\\t<tr>\\n\\t\\t\\t\\t<td>5</td>\\n\\t\\t\\t\\t<td>John</td>\\n\\t\\t\\t\\t<td>Snow</td>\\n\\t\\t\\t\\t<td>@dunno</td>\\n\\t\\t\\t</tr>\\n\\t\\t\\t<tr>\\n\\t\\t\\t\\t<td>6</td>\\n\\t\\t\\t\\t<td>Tim</td>\\n\\t\\t\\t\\t<td>Bean</td>\\n\\t\\t\\t\\t<td>@timbean</td>\\n\\t\\t\\t</tr>\\n\\t\\t\\t</tbody>\\n\\t\\t</table>\\n\\t</div>\\n\\n\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t</div>\\n\\t\\t</div>\\n\\t</div>\\n\\n\\t<div class=\"clearfix\"></div>\\n\\t<div class=\"push\"></div>\\n</div>\\n\\n<div class=\"container-fluid footer\" id=\"layout-footer\">\\n\\t<div class=\"container\">\\n\\t\\t<div class=\"row\">\\n\\t\\t\\t<div class=\"col-md-3\">\\n\\t\\t\\t\\t<ul>\\n\\t\\t\\t\\t\\t<li><p>Products</p></li>\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"/\">Web Scraper browser extension</a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"/pricing\">Web Scraper Cloud</a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t</ul>\\n\\t\\t\\t</div>\\n\\t\\t\\t<div class=\"col-md-3\">\\n\\t\\t\\t\\t<ul>\\n\\t\\t\\t\\t\\t<li><p>Company</p></li>\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"/about-us\">About us</a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"/contact\">Contact</a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"/privacy-policy\">Website Privacy Policy</a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"/extension-privacy-policy\">Browser Extension Privacy Policy</a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"https://webscraper.io/downloads/Web_Scraper_Media_Kit.zip\">Media kit</a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<li><a href=\"/jobs\">Jobs</a></li>\\n\\t\\t\\t\\t</ul>\\n\\t\\t\\t</div>\\n\\t\\t\\t<div class=\"col-md-3\">\\n\\t\\t\\t\\t<ul>\\n\\t\\t\\t\\t\\t<li><p>Resources</p></li>\\n\\t\\t\\t\\t\\t<li><a href=\"/blog\">Blog</a></li>\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"/documentation\">Documentation</a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"/tutorials\">Video Tutorials</a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"/screenshots\">Screenshots</a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"/test-sites\">Test Sites</a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a target=\"_blank\" href=\"https://forum.webscraper.io/\" rel=\"noopener\">Forum</a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t</ul>\\n\\t\\t\\t</div>\\n\\t\\t\\t<div class=\"col-md-3\">\\n\\t\\t\\t\\t<ul>\\n\\t\\t\\t\\t\\t<li><p>CONTACT US</p></li>\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"mailto:info@webscraper.io\">info@webscraper.io</a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t<li>Ubelu 5-71,<br> Adazi, Latvia, LV-2164</li>\\n\\t\\t\\t\\t</ul>\\n\\t\\t\\t\\t<ul class=\"smedia\">\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"https://www.facebook.com/webscraperio/\" target=\"_blank\" rel=\"noopener\"><img src=\"/img/fbicon.png\" alt=\"Web Scraper on Facebook\"></a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t<li>\\n\\t\\t\\t\\t\\t\\t<a href=\"https://twitter.com/webscraperio\" target=\"_blank\" rel=\"noopener\"><img src=\"/img/twicon.png\" alt=\"Web Scraper on Twitter\"></a>\\n\\t\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t\\t\\n\\n\\t\\t\\t\\t</ul>\\n\\t\\t\\t</div>\\n\\t\\t</div>\\n\\t\\t<div class=\"row\">\\n\\t\\t\\t<div class=\"col-md-12\">\\n\\t\\t\\t\\t<p class=\"copyright\">Copyright &copy 2023\\n\\t\\t\\t\\t\\t<a href=\"#\">Web Scraper</a> | All rights\\n\\t\\t\\t\\t\\treserved | Made by zoom59</p>\\n\\t\\t\\t</div>\\n\\t\\t</div>\\n\\t</div>\\n</div>\\n\\n\\n</body>\\n</html>\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beautiful Soup\n",
    "\n",
    "Beautiful Soup is a Python library for parsing HTML and XML documents. It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a popular Python library used for web scraping. It allows you to parse HTML and XML documents, and navigate through their contents in a structured way.\n",
    "\n",
    "\n",
    "#### Get page title\n",
    "\n",
    "It's the same title as we can find in our Tab name in browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Web Scraper Test Sites</title>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Web Scraper Test Sites'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference between `find` and `find_all` methods\n",
    "`find` returns first found item that matches given argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h2>Semantically correct table with thead and tbody</h2>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2 = soup.find('h2')\n",
    "h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_all` returns list of all tags that match given argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<h1>Test Sites</h1>, <h1>Table playground</h1>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1s = soup.find_all('h1')\n",
    "print(type(h1s))\n",
    "\n",
    "h1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sites\n",
      "Table playground\n"
     ]
    }
   ],
   "source": [
    "# Define the type of the iterated value\n",
    "h1: element.Tag\n",
    "\n",
    "for h1 in h1s:\n",
    "    print(h1.get_text())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect all tables from the page\n",
    "\n",
    "`find` and `find_all` methods receive an optional second argument.\n",
    "\n",
    "In this argument we pass a dictionary with defined HTML tag attributes we are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = soup.find_all('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-bordered\">\n",
       "<thead>\n",
       "<tr>\n",
       "<th>#</th>\n",
       "<th>First Name</th>\n",
       "<th>Last Name</th>\n",
       "<th>Username</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>1</td>\n",
       "<td>Mark</td>\n",
       "<td>Otto</td>\n",
       "<td>@mdo</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>2</td>\n",
       "<td>Jacob</td>\n",
       "<td>Thornton</td>\n",
       "<td>@fat</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>3</td>\n",
       "<td>Larry</td>\n",
       "<td>the Bird</td>\n",
       "<td>@twitter</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   # First Name Last Name  Username\n",
       " 0  1       Mark      Otto      @mdo\n",
       " 1  2      Jacob  Thornton      @fat\n",
       " 2  3      Larry  the Bird  @twitter]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_html(tables[0].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Harry</td>\n",
       "      <td>Potter</td>\n",
       "      <td>@hp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>John</td>\n",
       "      <td>Snow</td>\n",
       "      <td>@dunno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Tim</td>\n",
       "      <td>Bean</td>\n",
       "      <td>@timbean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # First Name Last Name  Username\n",
       "0  4      Harry    Potter       @hp\n",
       "1  5       John      Snow    @dunno\n",
       "2  6        Tim      Bean  @timbean"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_html(tables[1].prettify())[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Higher specification for scraped element\n",
    "\n",
    "To get more specific element we can use `find` method and support it with more specific attributes. Lets scrape navigation sidebar from the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ul class=\"nav\" id=\"side-menu\">\n",
       "<li>\n",
       "<a class=\"table-nav-button semantically-correct-button active\" href=\"/test-sites/tables/tables-semantically-correct\">Semantically correct tables</a>\n",
       "</li>\n",
       "<li>\n",
       "<a class=\"table-nav-button button-without-thead\" href=\"/test-sites/tables/tables-without-thead\">Tables without the thead tag</a>\n",
       "</li>\n",
       "<li>\n",
       "<a class=\"table-nav-button button-multiple-headers\" href=\"/test-sites/tables/tables-multiple-header-rows\">Tables with multiple header rows</a>\n",
       "</li>\n",
       "</ul>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navigation = soup.find('ul', {'id': 'side-menu'})\n",
    "navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"table-nav-button semantically-correct-button active\" href=\"/test-sites/tables/tables-semantically-correct\">Semantically correct tables</a>,\n",
       " <a class=\"table-nav-button button-without-thead\" href=\"/test-sites/tables/tables-without-thead\">Tables without the thead tag</a>,\n",
       " <a class=\"table-nav-button button-multiple-headers\" href=\"/test-sites/tables/tables-multiple-header-rows\">Tables with multiple header rows</a>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navigation.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/test-sites/tables/tables-semantically-correct\n",
      "/test-sites/tables/tables-without-thead\n",
      "/test-sites/tables/tables-multiple-header-rows\n"
     ]
    }
   ],
   "source": [
    "for link in navigation.find_all('a'):\n",
    "    print(link.attrs['href'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More advanced web scraping - Online Shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">**TASK**</span>\n",
    "\n",
    "Scrape the following data from the [Online Shop](https://webscraper.io/test-sites/e-commerce/allinone/computers/laptops) and save it in a DataFrame and then export it to a sqlite database:\n",
    "\n",
    "    - Product name\n",
    "    - Product price\n",
    "    - Product rating\n",
    "    - Product number of reviews\n",
    "    - Product URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://webscraper.io/test-sites/e-commerce/allinone/computers/laptops'\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.content)\n",
    "\n",
    "# Code goes here...\n",
    "\n",
    "\n",
    "# Get element that wraps the product cards\n",
    "product_cards = ...\n",
    "\n",
    "\n",
    "# Loop over product cards and extract the data\n",
    "for product in product_cards:\n",
    "  ...\n",
    "\n",
    "\n",
    "# Create new database with the name 'products.db'\n",
    "engine = create_engine('sqlite:///products.db')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
